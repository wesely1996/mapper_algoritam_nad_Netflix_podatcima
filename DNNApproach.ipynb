{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2151e102",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import argparse\n",
    "from collections import deque\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from keras.layers import Input, Embedding, Reshape, Dot, Concatenate, Dense, Dropout\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1833a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_user_data(data_path):\n",
    "    r\"\"\"Reads user data and refine it.\"\"\"\n",
    "    df_raw = pd.read_csv(data_path, header=None, names=[\"User\", \"Rating\", \"Date\"], usecols=[0, 1, 2])\n",
    "\n",
    "    tmp_movies = df_raw[df_raw[\"Rating\"].isna()][\"User\"].reset_index()\n",
    "    movie_indices = [[index, int(movie[:-1])] for index, movie in tmp_movies.values]\n",
    "\n",
    "    shifted_movie_indices = deque(movie_indices)\n",
    "    shifted_movie_indices.rotate(-1)\n",
    "\n",
    "    user_data = []\n",
    "    for [df_id_1, movie_id], [df_id_2, next_movie_id] in zip(movie_indices, shifted_movie_indices):\n",
    "        if df_id_1<df_id_2:\n",
    "            tmp_df = df_raw.loc[df_id_1+1:df_id_2-1].copy()\n",
    "        else:\n",
    "            tmp_df = df_raw.loc[df_id_1+1:].copy()\n",
    "            \n",
    "        tmp_df[\"Movie\"] = movie_id\n",
    "        user_data.append(tmp_df)\n",
    "\n",
    "    df = pd.concat(user_data)\n",
    "    print(f\"Shape of raw User-Ratings: {df.shape}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7750c3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data(df, movie_rating_threshold=10000, user_rating_threshold=200):\n",
    "    r\"\"\"Discard outliers from data in both movies and users.\"\"\"\n",
    "    filter_movies = (df[\"Movie\"].value_counts() > movie_rating_threshold)\n",
    "    filter_movies = filter_movies[filter_movies].index.tolist()\n",
    "\n",
    "    filter_users = (df[\"User\"].value_counts() > user_rating_threshold)\n",
    "    filter_users = filter_users[filter_users].index.tolist()\n",
    "\n",
    "    df_filtered = df[(df['Movie'].isin(filter_movies)) & (df['User'].isin(filter_users))]\n",
    "\n",
    "    print(f\"Shape of filtered User-Ratings: {df_filtered.shape}\")\n",
    "\n",
    "    return df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb72de4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_test_split(df_filtered, n=100000):\n",
    "    r\"\"\"Splits dataframe into training and test.\"\"\"\n",
    "    df_filtered = df_filtered.drop('Date', axis=1).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    # splits data into training and test\n",
    "    df_train = df_filtered[:-n]\n",
    "    df_test = df_filtered[-n:]\n",
    "\n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "302bc166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT: not used for DNN approach\n",
    "def make_data_sparse(df):\n",
    "    df_p = df.pivot_table(index=\"User\", columns=\"Movie\", values=\"Rating\", fill_value=0)\n",
    "\n",
    "    print(f\"Shape of User-Movie: {df_p.shape}\")\n",
    "\n",
    "    return df_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de4d96f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_movie_titles(data_path):\n",
    "    r\"\"\"Reads movie titles and returns dataframe.\"\"\"\n",
    "    movie_titles = pd.read_csv(data_path, \n",
    "                               encoding=\"ISO-8859-1\", \n",
    "                               header=None, \n",
    "                               names=[\"Id\", \"Year\", \"Name\"]).set_index(\"Id\")\n",
    "\n",
    "    print(f\"Shape of Movie-Titles: {movie_titles.shape}\")\n",
    "\n",
    "    return movie_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1b53f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Movie-Titles: (17770, 2)\n",
      "Shape of raw User-Ratings: (24053764, 4)\n",
      "Shape of filtered User-Ratings: (4178032, 4)\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"./data\"\n",
    "data_path = os.path.join(data_dir, \"combined_data_1.txt\")\n",
    "# data_path = os.path.join(data_dir, \"combined_data_all.txt\")\n",
    "\n",
    "movie_titles = fetch_movie_titles(os.path.join(data_dir, \"movie_titles.csv\"))\n",
    "\n",
    "df_raw = fetch_user_data(data_path)\n",
    "df_filtered = filter_data(df_raw)\n",
    "df_train, df_test = create_train_test_split(df_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31f998f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw number of users: 470758\n",
      "Raw number of movies: 4499\n"
     ]
    }
   ],
   "source": [
    "print(f\"Raw number of users: {len(df_raw['User'].unique())}\")\n",
    "print(f\"Raw number of movies: {len(df_raw['Movie'].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66b05017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 20828\n",
      "Number of movies: 491\n"
     ]
    }
   ],
   "source": [
    "# will map all IDs to [0, N]\n",
    "user_id_mapping = {unique_id: i for i, unique_id in enumerate(df_filtered[\"User\"].unique())}\n",
    "movie_id_mapping = {unique_id: i for i, unique_id in enumerate(df_filtered[\"Movie\"].unique())}\n",
    "\n",
    "train_user_data = df_train[\"User\"].map(user_id_mapping)\n",
    "train_movie_data = df_train[\"Movie\"].map(movie_id_mapping)\n",
    "\n",
    "# same mapping ised for both training and test data\n",
    "test_user_data = df_test[\"User\"].map(user_id_mapping)\n",
    "test_movie_data = df_test[\"Movie\"].map(movie_id_mapping)\n",
    "\n",
    "n_users = len(user_id_mapping)\n",
    "print(f\"Number of users: {n_users}\")\n",
    "\n",
    "n_movies = len(movie_id_mapping)\n",
    "print(f\"Number of movies: {n_movies}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5605dd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_embedding_size = 12\n",
    "movie_embedding_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e60592dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id_input = Input(shape=[1], name=\"user\")\n",
    "movie_id_input = Input(shape=[1], name=\"movie\")\n",
    "\n",
    "# Create embedding layers for users and movies\n",
    "user_embedding = Embedding(output_dim=user_embedding_size, \n",
    "                           input_dim=n_users,\n",
    "                           input_length=1, \n",
    "                           name=\"user_embedding\")(user_id_input)\n",
    "movie_embedding = Embedding(output_dim=movie_embedding_size, \n",
    "                            input_dim=n_movies,\n",
    "                            input_length=1, \n",
    "                            name=\"item_embedding\")(movie_id_input)\n",
    "\n",
    "# reshaping because embedding's output will have redundant dimension\n",
    "user_vector = Reshape([user_embedding_size])(user_embedding)\n",
    "movie_vector = Reshape([movie_embedding_size])(movie_embedding)\n",
    "\n",
    "# input to model will be embedding of both movie and user\n",
    "concat_input = Concatenate()([user_vector, movie_vector])\n",
    "\n",
    "# model is shallow MLP\n",
    "dense1 = Dense(256)(concat_input)\n",
    "dropout1 = Dropout(0.5)(dense1, training=True)\n",
    "dense2 = Dense(32)(dropout1)\n",
    "y = Dense(1)(dense2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8fd9cb8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7169/7169 [==============================] - 18s 2ms/step - loss: 0.8841 - val_loss: 0.8248\n"
     ]
    }
   ],
   "source": [
    "# init model\n",
    "model = Model(inputs=[user_id_input, movie_id_input], outputs=y)\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "\n",
    "# train model\n",
    "train_history = model.fit(x=[train_user_data, train_movie_data],\n",
    "                          y=df_train[\"Rating\"],\n",
    "                          batch_size=512, \n",
    "                          epochs=1,\n",
    "                          validation_split=0.1,\n",
    "                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ed3d9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict([test_user_data, test_movie_data])\n",
    "y_true = df_test[\"Rating\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fb77a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on test set: 0.8177500384141613\n",
      "RMSE on test set: 0.9042953269890104\n"
     ]
    }
   ],
   "source": [
    "mse = mean_squared_error(y_pred=y_pred, y_true=y_true)\n",
    "print(f\"MSE on test set: {mse}\")\n",
    "\n",
    "rmse = np.sqrt(mse)\n",
    "print(f\"RMSE on test set: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8baf460c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_forward_passes = 5\n",
    "recommend_threshold = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c35edf1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recommend_preds shape: (5, 100000)\n"
     ]
    }
   ],
   "source": [
    "recommend_preds = []\n",
    "for i in range(n_forward_passes):\n",
    "    y_pred = model.predict([test_user_data, test_movie_data])\n",
    "\n",
    "    recommend_pred = np.squeeze(y_pred)\n",
    "    min_pred = np.min(recommend_pred)\n",
    "    max_pred = np.max(recommend_pred)\n",
    "    recommend_pred = (recommend_pred - min_pred) / (max_pred - min_pred)\n",
    "    recommend_preds.append(recommend_pred)\n",
    "\n",
    "recommend_preds = np.array(recommend_preds)\n",
    "print(f\"recommend_preds shape: {recommend_preds.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3ec2354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recommend_true shape: (100000, 1)\n"
     ]
    }
   ],
   "source": [
    "recommend_true = np.squeeze(y_true) / 5\n",
    "recommend_true = recommend_true >= recommend_threshold\n",
    "recommend_true = np.intp(recommend_true).astype(np.float32)\n",
    "recommend_true = np.expand_dims(recommend_true, axis=1)\n",
    "print(f\"recommend_true shape: {recommend_true.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01e3b330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating statistics\n",
    "recommend_std = np.std(recommend_preds, axis=0).reshape(-1, 1)\n",
    "recommend_mean = np.mean(recommend_preds, axis=0).reshape(-1, 1)\n",
    "recommend_modus = (np.mean(recommend_preds >= recommend_threshold, axis=0) >= recommend_threshold).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "193bcc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensuring equality of shapes\n",
    "assert recommend_std.shape == recommend_mean.shape\n",
    "assert recommend_std.shape == recommend_modus.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e479d7dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intermediate shape: (100000, 32)\n"
     ]
    }
   ],
   "source": [
    "# creating submodel for gathering intermediate activations\n",
    "dense_1_model = Model(inputs=model.input, outputs=model.get_layer(\"dense_1\").output)\n",
    "intermediate_preds = dense_1_model.predict([test_user_data, test_movie_data])\n",
    "print(f\"Intermediate shape: {intermediate_preds.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "677de7d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Projection shape: (100000, 2)\n"
     ]
    }
   ],
   "source": [
    "projection_preds = np.c_[recommend_std, np.abs(recommend_true - recommend_mean)]\n",
    "print(f\"Projection shape: {projection_preds.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c2864063",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kmapper as km\n",
    "from sklearn.cluster import AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2f378c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KeplerMapper(verbose=2)\n",
      "Mapping on data shaped (100000, 32) using lens shaped (100000, 2)\n",
      "\n",
      "Minimal points in hypercube before clustering: 2\n",
      "Creating 100 hypercubes.\n",
      "   > Found 2 clusters in hypercube 0.\n",
      "   > Found 2 clusters in hypercube 1.\n",
      "   > Found 2 clusters in hypercube 2.\n",
      "   > Found 2 clusters in hypercube 3.\n",
      "   > Found 2 clusters in hypercube 4.\n",
      "   > Found 2 clusters in hypercube 5.\n",
      "   > Found 2 clusters in hypercube 6.\n",
      "   > Found 2 clusters in hypercube 7.\n",
      "   > Found 2 clusters in hypercube 8.\n",
      "   > Found 2 clusters in hypercube 9.\n",
      "   > Found 2 clusters in hypercube 10.\n",
      "   > Found 2 clusters in hypercube 11.\n",
      "   > Found 2 clusters in hypercube 12.\n",
      "   > Found 2 clusters in hypercube 13.\n",
      "   > Found 2 clusters in hypercube 14.\n",
      "   > Found 2 clusters in hypercube 15.\n",
      "   > Found 2 clusters in hypercube 16.\n",
      "   > Found 2 clusters in hypercube 17.\n",
      "   > Found 2 clusters in hypercube 18.\n",
      "   > Found 2 clusters in hypercube 19.\n",
      "   > Found 2 clusters in hypercube 20.\n",
      "   > Found 2 clusters in hypercube 21.\n",
      "   > Found 2 clusters in hypercube 22.\n",
      "   > Found 2 clusters in hypercube 23.\n"
     ]
    }
   ],
   "source": [
    "mapper = km.KeplerMapper(verbose=2)\n",
    "G = mapper.map(projection_preds,\n",
    "               intermediate_preds,\n",
    "               clusterer=AgglomerativeClustering(n_clusters=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36c83ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: use these colors somehow mapper\n",
    "colors = np.sqrt((recommend_true - recommend_mean) ** 2)\n",
    "colors = np.squeeze(colors).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fece0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = mapper.visualize(G,\n",
    "                     lens=projection_preds,\n",
    "                     lens_names=[\"STD\", \"L1\"],\n",
    "                     title=\"STD vs. L1\",\n",
    "                     path_html=\"visualization.html\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "netflix38",
   "language": "python",
   "name": "netflix38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
